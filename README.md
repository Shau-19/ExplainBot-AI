#[ ExplainBot AI](https://explainbot-ai-v1.onrender.com)

> An agentic document intelligence system that converts technical documents into text, audio, or synchronized video explanations â€” using a custom-built multi-agent pipeline, not a single API call.
---

## ğŸ¥ Live Demo

[â–¶ï¸ Click here to watch the full demo](assets/video_1771598634.mp4)



ExplainBot dynamically selects the best explanation format based on query intent â€” text, narrated audio, or fully synchronized explainer video with rendered architecture diagrams.
---

## The Problem It Solves

Technical documents are dense. Most AI tools summarize them into walls of text. ExplainBot AI analyzes the intent of your question and picks the right format â€” a definition gets clean text, a process gets audio narration, a system flow gets a fully synchronized explainer video with a rendered architecture diagram.

---

## How It Works

```
User Query
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Decision Agent â”‚  Analyzes query intent â†’ text / audio / video
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                           â”‚
    â–¼                           â–¼
Content Agent              Video Agent
Multilingual explanation   Per-scene narration scripts
    â”‚                           â”‚
    â–¼                      â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
Hybrid TTS                 â”‚                   â”‚
ElevenLabs â†’ OpenAI        Diagram Service     TTS per scene
                           Mermaid â†’ PNG       ElevenLabs â†’ OpenAI
                                â”‚                   â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â–¼
                                   Video Service
                                   MoviePy composer
                                   Scene-by-scene sync
```

### Key Engineering Decisions

**Scene-by-scene A/V sync** â€” most video generators produce one long audio track over disconnected visuals. ExplainBot generates a separate narration and audio clip per scene. Scene duration is read from the actual audio file â€” not estimated. What you see always matches what you hear.

**Principle-based prompt routing** â€” the decision agent uses a reasoning-based prompt, not hardcoded examples. This generalizes better across query types and languages.

**Persistent TTS fallback** â€” when ElevenLabs quota is exhausted, the error is caught, flagged, and written to disk. All future requests skip ElevenLabs silently. No retry loops, no downtime.

**Multi-document context** â€” documents are stored in a session dictionary and merged with separators before being passed to the LLM. Cross-document queries work out of the box.

---

## Features

| Feature | Detail |
|---|---|
| Multi-modal output | Text, audio narration, synchronized video |
| Multi-document | Query across multiple PDFs/TXTs simultaneously |
| Auto language detection | 9 languages â€” Hindi (Devanagari), Spanish, German, French and more |
| PDF export | ReportLab-styled export for every text response |
| Query history | Session-level history, restore output without regenerating |
| Hybrid TTS | ElevenLabs primary â†’ OpenAI fallback, quota persisted to disk |
| Rate limiting | Configurable daily caps with live frontend display |
| Single server | Frontend served by FastAPI â€” no separate process needed |

---

## Stack

```
LLM inference      Groq Â· llama-3.1-8b-instant
TTS primary        ElevenLabs Â· eleven_multilingual_v2
TTS fallback       OpenAI Â· tts-1-hd
Video composition  MoviePy
Diagram rendering  Mermaid.ink API
Backend            FastAPI
PDF generation     ReportLab
Language detect    langdetect
Frontend           Vanilla JS Â· Tailwind CSS
```

---

## Project Structure

```
explainbot-ai/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                  # FastAPI app, endpoints, rate limiting
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ decision_agent.py    # Query routing â€” text / audio / video
â”‚   â”‚   â”œâ”€â”€ content_agent.py     # Multilingual explanation generation
â”‚   â”‚   â””â”€â”€ video_agent.py       # Scene planning + per-scene narration
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ tts_service.py       # Hybrid TTS + quota tracking
â”‚       â”œâ”€â”€ video_service.py     # Scene rendering + composition
â”‚       â””â”€â”€ diagram_service.py   # Mermaid â†’ PNG
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html
â”‚   â””â”€â”€ app.js
â”œâ”€â”€ .env.example
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

---

## Local Setup

**Requirements:** Python 3.10+, ffmpeg on PATH

```bash
git clone https://github.com/Shau-19/explainbot-ai.git
cd explainbot-ai/backend
pip install -r requirements.txt
cp ../.env.example .env   # fill in your keys
uvicorn main:app --reload
```

Open `http://localhost:8000` â€” API and frontend on the same port.

---

## Docker Setup

```bash
cp .env.example .env   # fill in your keys
docker-compose up --build
```

Open `http://localhost:8000`

---

## Environment Variables

```env
GROQ_API_KEY=
ELEVENLABS_API_KEY=
OPENAI_API_KEY=
```

---

## API Reference

Full interactive docs at `http://localhost:8000/docs`

| Method | Endpoint | Description |
|---|---|---|
| POST | `/api/upload` | Upload PDF or TXT |
| DELETE | `/api/document/{filename}` | Remove a document |
| GET | `/api/documents` | List loaded documents |
| POST | `/api/explain` | Generate text or audio explanation |
| POST | `/api/generate-video` | Generate synchronized video |
| GET | `/api/usage` | Rate limit status |
| GET | `/api/export/{filename}` | Download PDF export |
| GET | `/api/audio/{filename}` | Serve audio |
| GET | `/api/video/{filename}` | Serve video |

---

## Sample Queries

| Query | Expected Output |
|---|---|
| `What is Proof of Work?` | Text |
| `How does a blockchain transaction work?` | Audio |
| `Walk me through the complete transaction flow` | Video |
| `à¤¬à¥à¤²à¥‰à¤•à¤šà¥‡à¤¨ à¤®à¥‡à¤‚ à¤¨à¥‹à¤¡à¥à¤¸ à¤•à¥€ à¤•à¥à¤¯à¤¾ à¤­à¥‚à¤®à¤¿à¤•à¤¾ à¤¹à¥ˆ?` | Hindi text |
| Upload 2 docs â†’ `Compare both architectures` | Cross-document text |

---

## Share Publicly

Without a server â€” use ngrok:

```bash
ngrok http 8000
```

With Docker on a VPS â€” just expose port 8000.

---

*MIT License*
